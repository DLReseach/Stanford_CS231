<p><img src="media/image1.jpeg" style="width:9.73125in;height:4.50625in" /></p>
<p>Segmentation and Attention</p>
<p><img src="media/image2.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 1 24 Feb 2016</p>
<blockquote>
<p><img src="media/image3.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image4.jpeg" style="width:9.02778in;height:3.71458in" /></p>
<ul>
<li><blockquote>
<p>Assignment 3 due tonight!</p>
</blockquote></li>
<li><blockquote>
<p>We are reading your milestones</p>
</blockquote></li>
</ul>
<p><img src="media/image5.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 2 24 Feb 2016</p>
<blockquote>
<p><img src="media/image6.jpeg" style="width:9.67222in;height:4.75278in" /></p>
<p><strong>Caffe</strong></p>
</blockquote>
<p><strong>Lasagne</strong></p>
<blockquote>
<p><strong>Torch</strong></p>
<p><strong>Theano</strong></p>
<p><strong>TensorFlow</strong></p>
</blockquote>
<p><strong>Keras</strong></p>
<p><img src="media/image7.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 3 24 Feb 2016</p>
<blockquote>
<p><img src="media/image8.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image9.jpeg" style="width:9.02778in;height:3.71458in" /></p>
<ul>
<li><blockquote>
<p>Segmentation</p>
</blockquote>
<ul>
<li><blockquote>
<p>Semantic Segmentation</p>
</blockquote></li>
<li><blockquote>
<p>Instance Segmentation</p>
</blockquote></li>
</ul></li>
<li><blockquote>
<p>(Soft) Attention</p>
</blockquote>
<ul>
<li><blockquote>
<p>Discrete locations</p>
</blockquote></li>
<li><blockquote>
<p>Continuous locations (Spatial Transformers)</p>
</blockquote></li>
</ul></li>
</ul>
<p><img src="media/image10.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 4 24 Feb 2016</p>
<blockquote>
<p><img src="media/image11.jpeg" style="width:9.02778in;height:4.55764in" /></p>
</blockquote>
<p><img src="media/image12.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 5 24 Feb 2016</p>
<blockquote>
<p><img src="media/image13.jpeg" style="width:10in;height:5.41389in" /></p>
</blockquote>
<p>New ImageNet Record today!</p>
<p>Szegedy et al, Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, arXiv 2016</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 6 24 Feb 2016</p>
<p><img src="media/image14.jpeg" style="width:9.27847in;height:4.42778in" /></p>
<p>1x7, 7x1 filters</p>
<p>Strided convolution AND max pooling</p>
<p>V = Valid convolutions (no padding)</p>
<p>9 layers</p>
</blockquote>
<p><img src="media/image15.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Szegedy et al, Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, arXiv 2016</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 7 24 Feb 2016</p>
<p><img src="media/image16.jpeg" style="width:9.02778in;height:4.42778in" /></p>
<p>3 layers</p>
<p>x4</p>
<p>4 x 3 layers</p>
<p>9 layers</p>
</blockquote>
<p><img src="media/image17.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Szegedy et al, Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, arXiv 2016</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 8 24 Feb 2016</p>
<p><img src="media/image18.jpeg" style="width:10in;height:5.41389in" /></p>
<p>4 layers</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>5 x 7 layers</td>
<td><blockquote>
<p>x7</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>3 layers</p>
<p>4 x 3 layers</p>
<p>9 layers</p>
</blockquote>
<p>Szegedy et al, Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, arXiv 2016</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 9 24 Feb 2016</p>
<p><img src="media/image19.jpeg" style="width:9.47639in;height:4.42778in" /></p>
<p>x3</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td>3 x 4 layers</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>4 layers</td>
<td></td>
</tr>
<tr class="odd">
<td>75</td>
<td>5 x 7 layers</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>3 layers</td>
<td></td>
</tr>
<tr class="odd">
<td>layers</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>4 x 3 layers</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>9 layers</td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image20.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Szegedy et al, Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, arXiv 2016</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 10 24 Feb 2016</p>
<p><img src="media/image22.jpeg" style="width:9.02778in;height:4.71319in" /></p>
<p>9 layers</p>
</blockquote>
<p><img src="media/image23.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 11 24 Feb 2016</p>
<blockquote>
<p><img src="media/image24.jpeg" style="width:9.02778in;height:4.74375in" /></p>
</blockquote>
<p>3 layers</p>
<blockquote>
<p>5 x 4 layers</p>
<p>9 layers</p>
</blockquote>
<p>x7</p>
<p><img src="media/image25.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 12 24 Feb 2016</p>
<blockquote>
<p><img src="media/image26.jpeg" style="width:9.02778in;height:4.71319in" /></p>
<p>3 layers</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>10 x 4 layers</td>
<td><blockquote>
<p>x10</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>3 layers</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>5 x 4 layers</p>
<p>9 layers</p>
</blockquote>
<p><img src="media/image27.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 13 24 Feb 2016</p>
<blockquote>
<p><img src="media/image28.jpeg" style="width:9.51389in;height:4.71319in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>5 x 4 layers</td>
<td><blockquote>
<p>x 5</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>3 layers</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>75 10 x 4 layers</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>layers</p>
<blockquote>
<p>3 layers</p>
<p>5 x 3 layers</p>
<p>9 layers</p>
</blockquote>
<p><img src="media/image29.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 14 24 Feb 2016</p>
<p><img src="media/image30.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image31.jpeg" style="width:4.33333in;height:3.30833in" /></p>
<blockquote>
<p>Residual and non-residual converge to</p>
<p>similar value, but residual learns faster</p>
</blockquote>
<p><img src="media/image32.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 15 24 Feb 2016</p>
<blockquote>
<p><img src="media/image33.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image34.jpeg" style="width:9.02778in;height:3.71458in" /></p>
<ul>
<li><blockquote>
<p>Segmentation</p>
</blockquote>
<ul>
<li><blockquote>
<p>Semantic Segmentation</p>
</blockquote></li>
<li><blockquote>
<p>Instance Segmentation</p>
</blockquote></li>
</ul></li>
<li><blockquote>
<p>(Soft) Attention</p>
</blockquote>
<ul>
<li><blockquote>
<p>Discrete locations</p>
</blockquote></li>
<li><blockquote>
<p>Continuous locations (Spatial Transformers)</p>
</blockquote></li>
</ul></li>
</ul>
<p><img src="media/image35.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 16 24 Feb 2016</p>
<p><img src="media/image36.jpeg" style="width:9.02778in;height:0.96528in" /></p>
<p>Segmentation</p>
<p><img src="media/image37.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 17 24 Feb 2016</p>
<blockquote>
<p><img src="media/image38.jpeg" style="width:8.45069in;height:0.71736in" /></p>
</blockquote>
<p><img src="media/image39.jpeg" style="width:9.58681in;height:2.80903in" /></p>
<table>
<tbody>
<tr class="odd">
<td><strong>Classification</strong></td>
<td><blockquote>
<p><strong>Classification</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>Object Detection</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>Segmentation</strong></p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p><strong>+ Localization</strong></p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image40.jpeg" style="width:9.58264in;height:0.45833in" /></p>
<blockquote>
<p>CAT CAT CAT, DOG, DUCK CAT, DOG, DUCK</p>
</blockquote>
<p><img src="media/image41.jpeg" style="width:10in;height:1.44861in" /></p>
<blockquote>
<p>Single object Multiple objects</p>
</blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 1818 24 Feb 2016</p>
<blockquote>
<p><img src="media/image42.jpeg" style="width:8.45069in;height:0.71736in" /></p>
</blockquote>
<p><img src="media/image43.jpeg" style="width:9.58681in;height:2.80903in" /></p>
<table>
<tbody>
<tr class="odd">
<td><strong>Classification</strong></td>
<td><blockquote>
<p><strong>Classification</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>Object Detection</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>Segmentation</strong></p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p><strong>+ Localization</strong></p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image44.jpeg" style="width:4.73333in;height:0.91597in" /></p>
<p>Lecture 8</p>
<p><img src="media/image45.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 1919 24 Feb 2016</p>
<blockquote>
<p><img src="media/image46.jpeg" style="width:8.45069in;height:0.71736in" /></p>
</blockquote>
<p><img src="media/image47.jpeg" style="width:9.58681in;height:2.80903in" /></p>
<table>
<tbody>
<tr class="odd">
<td><strong>Classification</strong></td>
<td><blockquote>
<p><strong>Classification</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>Object Detection</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>Segmentation</strong></p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p><strong>+ Localization</strong></p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image48.jpeg" style="width:2.11111in;height:0.52014in" /></p>
<blockquote>
<p>Today</p>
</blockquote>
<p><img src="media/image49.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 2020 24 Feb 2016</p>
<blockquote>
<p><img src="media/image50.jpeg" style="width:9.35556in;height:4.47639in" /></p>
<p>Label every pixel!</p>
<p>Don’t differentiate instances (cows)</p>
<p>Classic computer vision problem</p>
</blockquote>
<p><img src="media/image51.jpeg" style="width:10in;height:0.90139in" /></p>
<p>Figure credit: Shotton et al, “TextonBoost for Image Understanding: Multi-Class Object Recognition and Segmentation by Jointly Modeling Texture, Layout, and Context”, IJCV 2007</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 21 24 Feb 2016</p>
<p><img src="media/image52.jpeg" style="width:9.64097in;height:4.46389in" /></p>
<p>Detect instances, give category, label pixels</p>
<p>“simultaneous detection and segmentation” (SDS)</p>
</blockquote>
<p><img src="media/image53.jpeg" style="width:0.79861in" /></p>
<blockquote>
<p>Lots of recent work</p>
<p>(MS-COCO)</p>
</blockquote>
<p><img src="media/image54.jpeg" style="width:10in;height:0.92361in" /></p>
<blockquote>
<p>Figure credit: Dai et al, “Instance-aware Semantic Segmentation via Multi-task Network Cascades”, arXiv 2015</p>
</blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 22 24 Feb 2016</p>
<p><img src="media/image55.jpeg" style="width:9.02778in;height:0.96528in" /></p>
<p>Semantic Segmentation</p>
<p><img src="media/image56.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 23 24 Feb 2016</p>
<blockquote>
<p><img src="media/image57.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image58.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 24 24 Feb 2016</p>
<blockquote>
<p><img src="media/image60.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image61.jpeg" style="width:1.83472in;height:0.74792in" /></p>
<blockquote>
<p>Extract</p>
<p>patch</p>
</blockquote>
<p><img src="media/image62.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 25 24 Feb 2016</p>
<blockquote>
<p><img src="media/image64.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image65.jpeg" style="width:3.75556in;height:0.74792in" /></p>
<blockquote>
<p>Extract Run through</p>
<p>patch a CNN</p>
</blockquote>
<p><img src="media/image66.jpeg" style="width:6.56667in;height:1.94583in" /></p>
<blockquote>
<p>CNN</p>
</blockquote>
<p><img src="media/image67.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 26 24 Feb 2016</p>
<blockquote>
<p><img src="media/image70.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image71.jpeg" style="width:5.72917in;height:0.74792in" /></p>
<blockquote>
<p>Extract Run through Classify</p>
<p>patch a CNN center pixel</p>
</blockquote>
<p><img src="media/image72.jpeg" style="width:8.47778in;height:1.94583in" /></p>
<blockquote>
<p>CNN <img src="media/image73.jpeg" style="width:0.61389in;height:0.22847in" /> COW</p>
</blockquote>
<p><img src="media/image74.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 27 24 Feb 2016</p>
<blockquote>
<p><img src="media/image78.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image79.jpeg" style="width:5.72917in;height:0.74792in" /></p>
<blockquote>
<p>Extract Run through Classify</p>
<p>patch a CNN center pixel</p>
</blockquote>
<p><img src="media/image80.jpeg" style="width:8.47778in;height:1.94583in" /></p>
<blockquote>
<p>CNN <img src="media/image81.jpeg" style="width:0.61389in;height:0.22847in" /> COW</p>
</blockquote>
<p><img src="media/image82.jpeg" style="width:4.47778in;height:2.35417in" /></p>
<blockquote>
<p>Repeat for</p>
<p>every pixel</p>
</blockquote>
<p><img src="media/image84.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 28 24 Feb 2016</p>
<blockquote>
<p><img src="media/image85.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image86.jpeg" style="width:3.89514in;height:0.96528in" /></p>
<p>Run “fully convolutional” network</p>
<p>to get all pixels at once</p>
<p><img src="media/image87.jpeg" style="width:9.42083in;height:1.88333in" /></p>
<p>Smaller output</p>
<table>
<tbody>
<tr class="odd">
<td>CNN</td>
<td><blockquote>
<p>due to pooling</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image88.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 29 24 Feb 2016</p>
<blockquote>
<p><img src="media/image93.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image94.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Farabet et al, “Learning Hierarchical Features for Scene Labeling,” TPAMI 2013</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 30 24 Feb 2016</p>
<p><img src="media/image96.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image97.jpeg" style="width:4.22778in;height:2.21458in" /></p>
<blockquote>
<p>Resize image to</p>
<p>multiple scales</p>
</blockquote>
<p><img src="media/image98.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Farabet et al, “Learning Hierarchical Features for Scene Labeling,” TPAMI 2013</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 31 24 Feb 2016</p>
<p><img src="media/image99.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image100.jpeg" style="width:6.73542in;height:2.30486in" /></p>
<table>
<tbody>
<tr class="odd">
<td>Resize image to</td>
<td><blockquote>
<p>Run one CNN</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>per scale</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>multiple scales</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image101.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Farabet et al, “Learning Hierarchical Features for Scene Labeling,” TPAMI 2013</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 32 24 Feb 2016</p>
<p><img src="media/image102.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image103.jpeg" style="width:6.73542in;height:2.30486in" /></p>
<table>
<tbody>
<tr class="odd">
<td>Resize image to</td>
<td><blockquote>
<p>Run one CNN</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>per scale</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>multiple scales</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Upscale outputs</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>and concatenate</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image104.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Farabet et al, “Learning Hierarchical Features for Scene Labeling,” TPAMI 2013</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 33 24 Feb 2016</p>
<p><img src="media/image105.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image106.jpeg" style="width:7.47361in;height:3.24653in" /></p>
<table>
<tbody>
<tr class="odd">
<td>Resize image to</td>
<td><blockquote>
<p>Run one CNN</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>per scale</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>multiple scales</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Upscale outputs</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>and concatenate</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>External “bottom-up”</p>
<p>segmentation</p>
</blockquote>
<p><img src="media/image107.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Farabet et al, “Learning Hierarchical Features for Scene Labeling,” TPAMI 2013</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 34 24 Feb 2016</p>
<p><img src="media/image108.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image109.jpeg" style="width:9.70625in;height:3.24653in" /></p>
<table>
<tbody>
<tr class="odd">
<td>Resize image to</td>
<td><blockquote>
<p>Run one CNN</p>
</blockquote></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>per scale</p>
</blockquote></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>multiple scales</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Upscale outputs</p>
</blockquote></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>and concatenate</p>
</blockquote></td>
<td><blockquote>
<p>Combine everything</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td><blockquote>
<p>for final outputs</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>External “bottom-up”</p>
<p>segmentation</p>
</blockquote>
<p><img src="media/image110.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Farabet et al, “Learning Hierarchical Features for Scene Labeling,” TPAMI 2013</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 35 24 Feb 2016</p>
<p><img src="media/image111.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image112.jpeg" style="width:3.07778in;height:2.09306in" /></p>
<blockquote>
<p>Apply CNN once to get labels</p>
</blockquote>
<p><img src="media/image113.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Pinheiro and Collobert, “Recurrent Convolutional Neural Networks for Scene Labeling”, ICML 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 36 24 Feb 2016</p>
<p><img src="media/image114.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image115.jpeg" style="width:3.1375in;height:3.00833in" /></p>
<blockquote>
<p>Apply CNN once to get labels</p>
<p>Apply AGAIN to</p>
<p>refine labels</p>
</blockquote>
<p><img src="media/image116.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Pinheiro and Collobert, “Recurrent Convolutional Neural Networks for Scene Labeling”, ICML 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 37 24 Feb 2016</p>
<p><img src="media/image117.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image118.jpeg" style="width:10in;height:4.38611in" /></p>
<blockquote>
<p>Apply CNN once to get labels</p>
<p>Apply AGAIN to</p>
<p>refine labels</p>
<p>And again!</p>
</blockquote>
<p>Pinheiro and Collobert, “Recurrent Convolutional Neural Networks for Scene Labeling”, ICML 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 38 24 Feb 2016</p>
<p><img src="media/image119.jpeg" style="width:10in;height:5.41389in" /></p>
<p>Same CNN weights:</p>
<p><strong>recurrent convolutional network</strong></p>
<p>Apply CNN once to get labels</p>
<p>Apply AGAIN to</p>
<p>refine labels</p>
<p>And again!</p>
</blockquote>
<p>Pinheiro and Collobert, “Recurrent Convolutional Neural Networks for Scene Labeling”, ICML 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 39 24 Feb 2016</p>
<p><img src="media/image120.jpeg" style="width:10in;height:5.41389in" /></p>
<p>Same CNN weights:</p>
<p><strong>recurrent convolutional network</strong></p>
<p>Apply CNN once to get labels</p>
<p>Apply AGAIN to</p>
<p>refine labels</p>
<p>And again! <img src="media/image121.jpeg" style="width:5.37986in;height:0.22847in" /> More iterations improve results</p>
</blockquote>
<p><img src="media/image122.jpeg" style="width:5.36319in" /></p>
<p>Pinheiro and Collobert, “Recurrent Convolutional Neural Networks for Scene Labeling”, ICML 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 40 24 Feb 2016</p>
<p><img src="media/image123.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image124.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Long, Shelhamer, and Darrell, “Fully Convolutional Networks for Semantic Segmentation”, CVPR 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 41 24 Feb 2016</p>
<p><img src="media/image126.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image127.jpeg" style="width:5.40556in;height:3.29931in" /></p>
<blockquote>
<p>Learnable upsampling!</p>
</blockquote>
<p><img src="media/image128.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Long, Shelhamer, and Darrell, “Fully Convolutional Networks for Semantic Segmentation”, CVPR 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 42 24 Feb 2016</p>
<p><img src="media/image129.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image130.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Long, Shelhamer, and Darrell, “Fully Convolutional Networks for Semantic Segmentation”, CVPR 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 43 24 Feb 2016</p>
<p><img src="media/image132.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image133.jpeg" style="width:7.33264in;height:3.13194in" /></p>
<blockquote>
<p>“skip</p>
<p>connections”</p>
</blockquote>
<p><img src="media/image134.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Long, Shelhamer, and Darrell, “Fully Convolutional Networks for Semantic Segmentation”, CVPR 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 44 24 Feb 2016</p>
<p><img src="media/image135.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image136.jpeg" style="width:9.22431in;height:3.35625in" /></p>
<blockquote>
<p>“skip</p>
<p>connections”</p>
<p>Skip connections = Better results</p>
</blockquote>
<p><img src="media/image137.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Long, Shelhamer, and Darrell, “Fully Convolutional Networks for Semantic Segmentation”, CVPR 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 45 24 Feb 2016</p>
<p><img src="media/image138.jpeg" style="width:9.02778in;height:1.35972in" /></p>
<p>Typical 3 x 3 convolution, stride 1 pad 1</p>
</blockquote>
<p><img src="media/image139.jpeg" style="width:5.38333in;height:2.18889in" /></p>
<blockquote>
<p>Input: 4 x 4 Output: 4 x 4</p>
</blockquote>
<p><img src="media/image140.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 46 24 Feb 2016</p>
<blockquote>
<p><img src="media/image141.jpeg" style="width:9.02778in;height:1.35972in" /></p>
<p>Typical 3 x 3 convolution, stride 1 pad 1</p>
</blockquote>
<p><img src="media/image142.jpeg" style="width:5.80417in;height:2.12847in" /></p>
<blockquote>
<p>Dot product</p>
<p>between filter</p>
<p>and input</p>
</blockquote>
<p><img src="media/image143.jpeg" style="width:1.70278in;height:0.42153in" /></p>
<blockquote>
<p>Input: 4 x 4 Output: 4 x 4</p>
</blockquote>
<p><img src="media/image145.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 47 24 Feb 2016</p>
<blockquote>
<p><img src="media/image146.jpeg" style="width:9.02778in;height:1.35972in" /></p>
<p>Typical 3 x 3 convolution, stride 1 pad 1</p>
</blockquote>
<p><img src="media/image147.jpeg" style="width:5.80417in;height:2.12847in" /></p>
<blockquote>
<p>Dot product</p>
<p>between filter</p>
<p>and input</p>
</blockquote>
<p><img src="media/image148.jpeg" style="width:1.70278in;height:0.42153in" /></p>
<blockquote>
<p>Input: 4 x 4 Output: 4 x 4</p>
</blockquote>
<p><img src="media/image150.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 48 24 Feb 2016</p>
<blockquote>
<p><img src="media/image151.jpeg" style="width:9.02778in;height:1.35972in" /></p>
<p>Typical 3 x 3 convolution, <strong>stride 2</strong> pad 1</p>
</blockquote>
<p><img src="media/image152.jpeg" style="width:5.38333in;height:2.16944in" /></p>
<blockquote>
<p>Input: 4 x 4 Output: 2 x 2</p>
</blockquote>
<p><img src="media/image153.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 49 24 Feb 2016</p>
<blockquote>
<p><img src="media/image154.jpeg" style="width:9.02778in;height:1.35972in" /></p>
<p>Typical 3 x 3 convolution, stride 2 pad 1</p>
</blockquote>
<p><img src="media/image155.jpeg" style="width:5.38542in;height:2.12847in" /></p>
<blockquote>
<p>Dot product</p>
<p>between filter</p>
<p>and input</p>
</blockquote>
<p><img src="media/image156.jpeg" style="width:1.70278in;height:0.42153in" /></p>
<blockquote>
<p>Input: 4 x 4 Output: 2 x 2</p>
</blockquote>
<p><img src="media/image158.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 50 24 Feb 2016</p>
<blockquote>
<p><img src="media/image159.jpeg" style="width:9.02778in;height:1.35972in" /></p>
<p>Typical 3 x 3 convolution, stride 2 pad 1</p>
</blockquote>
<p><img src="media/image160.jpeg" style="width:5.39375in;height:2.12847in" /></p>
<blockquote>
<p>Dot product</p>
<p>between filter</p>
<p>and input</p>
</blockquote>
<p><img src="media/image161.jpeg" style="width:1.70278in;height:0.42153in" /></p>
<blockquote>
<p>Input: 4 x 4 Output: 2 x 2</p>
</blockquote>
<p><img src="media/image163.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 51 24 Feb 2016</p>
<blockquote>
<p><img src="media/image164.jpeg" style="width:9.02778in;height:1.35972in" /></p>
<p>3 x 3 “deconvolution”, stride 2 pad 1</p>
</blockquote>
<p><img src="media/image165.jpeg" style="width:0.84792in;height:0.86875in" /></p>
<blockquote>
<p>Input: 2 x 2 Output: 4 x 4</p>
</blockquote>
<p><img src="media/image168.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 52 24 Feb 2016</p>
<blockquote>
<p><img src="media/image169.jpeg" style="width:9.02778in;height:1.35972in" /></p>
<p>3 x 3 “deconvolution”, stride 2 pad 1</p>
</blockquote>
<p><img src="media/image170.jpeg" style="width:4.95556in;height:2.14792in" /></p>
<blockquote>
<p>Input gives</p>
<p>weight for</p>
<p>filter</p>
</blockquote>
<p><img src="media/image171.jpeg" style="width:1.70278in;height:0.42153in" /></p>
<blockquote>
<p>Input: 2 x 2 Output: 4 x 4</p>
</blockquote>
<p><img src="media/image173.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 53 24 Feb 2016</p>
<blockquote>
<p><img src="media/image174.jpeg" style="width:9.02778in;height:1.35972in" /></p>
<p>3 x 3 “deconvolution”, stride 2 pad 1</p>
</blockquote>
<p><img src="media/image175.jpeg" style="width:4.97153in;height:2.14792in" /></p>
<blockquote>
<p>Input gives</p>
<p>weight for</p>
<p>filter</p>
</blockquote>
<p><img src="media/image176.jpeg" style="width:1.70278in;height:0.42153in" /></p>
<blockquote>
<p>Input: 2 x 2 Output: 4 x 4</p>
</blockquote>
<p><img src="media/image178.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 54 24 Feb 2016</p>
<blockquote>
<p><img src="media/image179.jpeg" style="width:9.02778in;height:3.75903in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>3 x 3 “deconvolution”, stride 2 pad 1</td>
<td><blockquote>
<p>Sum where</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>output overlaps</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image180.jpeg" style="width:1.58889in" /></p>
<blockquote>
<p>Input gives</p>
<p>weight for</p>
<p>filter</p>
</blockquote>
<p><img src="media/image181.jpeg" style="width:1.70278in;height:0.42153in" /></p>
<blockquote>
<p>Input: 2 x 2 Output: 4 x 4</p>
</blockquote>
<p><img src="media/image183.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 55 24 Feb 2016</p>
<blockquote>
<p><img src="media/image184.jpeg" style="width:9.46806in;height:4.80278in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>3 x 3 “deconvolution”, stride 2 pad 1</td>
<td><blockquote>
<p>Sum where</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>output overlaps</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>Same as backward pass for</p>
<p>normal convolution!</p>
</blockquote>
<p><img src="media/image185.jpeg" style="width:1.58889in" /></p>
<blockquote>
<p>Input gives</p>
<p>weight for</p>
<p>filter</p>
<p>Input: 2 x 2 Output: 4 x 4</p>
</blockquote>
<p><img src="media/image186.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 56 24 Feb 2016</p>
<blockquote>
<p><img src="media/image187.jpeg" style="width:9.46806in;height:4.80278in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td><blockquote>
<p>3 x 3 “deconvolution”, stride 2 pad 1</p>
</blockquote></td>
<td><blockquote>
<p>Sum where</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>output overlaps</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>Same as backward pass for</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>normal convolution!</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>“Deconvolution” is a bad</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>Input gives</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>weight for</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>name, already defined as</p>
</blockquote></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>filter</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>“inverse of convolution”</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p><strong>Better names:</strong></p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>convolution transpose,</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>Input: 2 x 2</td>
<td><blockquote>
<p>Output: 4 x 4</p>
</blockquote></td>
<td><blockquote>
<p>backward strided convolution,</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image188.jpeg" style="width:1.58889in" /></p>
<blockquote>
<p>1/2 strided convolution,</p>
<p>upconvolution</p>
</blockquote>
<p><img src="media/image189.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 57 24 Feb 2016</p>
<blockquote>
<p><img src="media/image190.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image191.jpeg" style="width:9.01736in;height:3.45347in" /></p>
<blockquote>
<p>Im et al, “Generating images with recurrent adversarial networks”, arXiv 2016</p>
</blockquote>
<p><img src="media/image192.jpeg" style="width:6.89792in;height:0.73264in" /></p>
<blockquote>
<p>Radford et al, “Unsupervised Representation Learning with Deep</p>
<p>Convolutional Generative Adversarial Networks”, ICLR 2016</p>
</blockquote>
<p><img src="media/image194.jpeg" style="width:10in;height:0.58889in" /></p>
<p>“Deconvolution” is a bad name, already defined as “inverse of convolution”</p>
<p><strong>Better names:</strong> convolution transpose, backward strided convolution, 1/2 strided convolution, upconvolution</p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 58 24 Feb 2016</p>
<blockquote>
<p><img src="media/image195.jpeg" style="width:9.72083in;height:4.80278in" /></p>
<p>Im et al, “Generating images with recurrent adversarial networks”, arXiv 2016</p>
<p>Radford et al, “Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks”, ICLR 2016</p>
</blockquote>
<p><img src="media/image196.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Great explanation</p>
<p>in appendix</p>
<blockquote>
<p>“Deconvolution” is a bad name, already defined as “inverse of convolution”</p>
<p><strong>Better names:</strong> convolution transpose, backward strided convolution, 1/2 strided convolution, upconvolution</p>
</blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 59 24 Feb 2016</p>
<blockquote>
<p><img src="media/image197.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image198.jpeg" style="width:7.6125in;height:2.02014in" /></p>
<p>Noh et al, “Learning Deconvolution Network for Semantic Segmentation”, ICCV 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 60 24 Feb 2016</p>
<p><img src="media/image200.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image201.jpeg" style="height:0.62569in" /></p>
<blockquote>
<p>Normal VGG “Upside down” VGG</p>
</blockquote>
<p><img src="media/image204.jpeg" style="width:10in;height:1.03611in" /></p>
<p>Noh et al, “Learning Deconvolution Network for Semantic Segmentation”, ICCV 2015</p>
<p>6 days of training on Titan X…</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 61 24 Feb 2016</p>
</blockquote>
<p><img src="media/image205.jpeg" style="width:9.02778in;height:0.96528in" /></p>
<p>Instance Segmentation</p>
<p><img src="media/image206.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 62 24 Feb 2016</p>
<blockquote>
<p><img src="media/image207.jpeg" style="width:9.64097in;height:4.46389in" /></p>
<p>Detect instances, give category, label pixels</p>
<p>“simultaneous detection and segmentation” (SDS)</p>
</blockquote>
<p><img src="media/image208.jpeg" style="width:0.79861in" /></p>
<blockquote>
<p>Lots of recent work</p>
<p>(MS-COCO)</p>
</blockquote>
<p><img src="media/image209.jpeg" style="width:10in;height:0.92361in" /></p>
<blockquote>
<p>Figure credit: Dai et al, “Instance-aware Semantic Segmentation via Multi-task Network Cascades”, arXiv 2015</p>
</blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 63 24 Feb 2016</p>
<blockquote>
<p><img src="media/image210.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image211.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Similar to R-CNN, but</p>
<p>with segments</p>
<p>Hariharan et al, “Simultaneous Detection and Segmentation”, ECCV 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 64 24 Feb 2016</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>Instance Segmentation</td>
<td><blockquote>
<p>with segments</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Similar to R-CNN, but</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="media/image213.jpeg" style="width:9.02778in;height:0.96528in" /></p>
<blockquote>
<p>External</p>
<p>Segment</p>
<p>proposals</p>
</blockquote>
<p><img src="media/image215.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Hariharan et al, “Simultaneous Detection and Segmentation”, ECCV 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 65 24 Feb 2016</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>Instance Segmentation</td>
<td><blockquote>
<p>with segments</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Similar to R-CNN, but</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="media/image216.jpeg" style="width:9.02778in;height:0.96528in" /></p>
<blockquote>
<p>External</p>
<p>Segment</p>
<p>proposals</p>
</blockquote>
<p><img src="media/image218.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Hariharan et al, “Simultaneous Detection and Segmentation”, ECCV 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 66 24 Feb 2016</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>Instance Segmentation</td>
<td><blockquote>
<p>with segments</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Similar to R-CNN, but</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="media/image219.jpeg" style="width:9.02778in;height:0.96528in" /></p>
<blockquote>
<p>External</p>
<p>Segment</p>
<p>proposals</p>
<p>Mask out background</p>
<p>with mean image</p>
</blockquote>
<p>Hariharan et al, “Simultaneous Detection and Segmentation”, ECCV 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 67 24 Feb 2016</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>Instance Segmentation</td>
<td><blockquote>
<p>with segments</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Similar to R-CNN, but</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="media/image221.jpeg" style="width:9.02778in;height:0.96528in" /></p>
<blockquote>
<p>External</p>
<p>Segment</p>
<p>proposals</p>
<p>Mask out background</p>
<p>with mean image</p>
</blockquote>
<p>Hariharan et al, “Simultaneous Detection and Segmentation”, ECCV 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 68 24 Feb 2016</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>Instance Segmentation</td>
<td><blockquote>
<p>with segments</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Similar to R-CNN, but</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="media/image223.jpeg" style="width:9.02778in;height:0.96528in" /></p>
<blockquote>
<p>External</p>
<p>Segment</p>
<p>proposals</p>
<p>Mask out background</p>
<p>with mean image</p>
</blockquote>
<p>Hariharan et al, “Simultaneous Detection and Segmentation”, ECCV 2014</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 69 24 Feb 2016</p>
<p><img src="media/image225.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image226.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Hariharan et al, “Hypercolumns for Object Segmentation and Fine-grained Localization”, CVPR 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 70 24 Feb 2016</p>
<p><img src="media/image228.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image229.jpeg" style="width:10in;height:4.32431in" /></p>
<p>Hariharan et al, “Hypercolumns for Object Segmentation and Fine-grained Localization”, CVPR 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 71 24 Feb 2016</p>
<p><img src="media/image230.jpeg" style="width:9.41458in;height:4.38958in" /></p>
<p>Similar to</p>
<p>Faster R-CNN</p>
<p>Won COCO 2015</p>
<p>challenge</p>
<p>(with ResNet)</p>
</blockquote>
<p><img src="media/image231.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Dai et al, “Instance-aware Semantic Segmentation via Multi-task Network Cascades”, arXiv 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 72 24 Feb 2016</p>
<p><img src="media/image232.jpeg" style="width:9.41458in;height:4.38958in" /></p>
<p>Similar to</p>
<p>Faster R-CNN</p>
<p>Won COCO 2015</p>
<p>challenge</p>
<p>(with ResNet)</p>
</blockquote>
<p><img src="media/image233.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Dai et al, “Instance-aware Semantic Segmentation via Multi-task Network Cascades”, arXiv 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 73 24 Feb 2016</p>
<p><img src="media/image234.jpeg" style="width:9.41458in;height:4.38958in" /></p>
<p>Similar to</p>
<p>Faster R-CNN</p>
</blockquote>
<p>Region proposal network (RPN)</p>
<blockquote>
<p>Won COCO 2015</p>
<p>challenge</p>
<p>(with ResNet)</p>
</blockquote>
<p><img src="media/image235.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Dai et al, “Instance-aware Semantic Segmentation via Multi-task Network Cascades”, arXiv 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 74 24 Feb 2016</p>
<p><img src="media/image236.jpeg" style="width:9.41458in;height:4.38958in" /></p>
<p>Similar to</p>
<p>Faster R-CNN</p>
</blockquote>
<p>Region proposal network (RPN)</p>
<blockquote>
<p>Reshape boxes to</p>
<p>fixed size,</p>
<p>figure / ground</p>
<p>logistic regression</p>
<p>Won COCO 2015</p>
<p>challenge</p>
<p>(with ResNet)</p>
</blockquote>
<p><img src="media/image237.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Dai et al, “Instance-aware Semantic Segmentation via Multi-task Network Cascades”, arXiv 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 75 24 Feb 2016</p>
<p><img src="media/image238.jpeg" style="width:9.41458in;height:4.38958in" /></p>
<p>Similar to</p>
<p>Faster R-CNN</p>
<p>Won COCO 2015 challenge (with ResNet)</p>
</blockquote>
<p>Region proposal network (RPN)</p>
<blockquote>
<p>Reshape boxes to</p>
<p>fixed size,</p>
<p>figure / ground</p>
<p>logistic regression</p>
<p>Mask out background,</p>
<p>predict object class</p>
</blockquote>
<p><img src="media/image239.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Dai et al, “Instance-aware Semantic Segmentation via Multi-task Network Cascades”, arXiv 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 76 24 Feb 2016</p>
<p><img src="media/image240.jpeg" style="width:9.47361in;height:4.38958in" /></p>
<p>Similar to</p>
<p>Faster R-CNN</p>
<p>Won COCO 2015 challenge (with ResNet)</p>
</blockquote>
<p>Region proposal network (RPN)</p>
<p>Reshape boxes to Learn entire model</p>
<blockquote>
<p>fixed size, end-to-end!</p>
<p>figure / ground</p>
<p>logistic regression</p>
<p>Mask out background,</p>
<p>predict object class</p>
</blockquote>
<p><img src="media/image241.jpeg" style="width:10in;height:0.93542in" /></p>
<p>Dai et al, “Instance-aware Semantic Segmentation via Multi-task Network Cascades”, arXiv 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 77 24 Feb 2016</p>
<p><img src="media/image242.jpeg" style="width:10in;height:5.41389in" /></p>
</blockquote>
<p>Dai et al, “Instance-aware Semantic Segmentation via Multi-task Network Cascades”, arXiv 2015</p>
<p><strong>Predictions</strong> <strong>Ground truth</strong></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 78 24 Feb 2016</p>
<p><img src="media/image243.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image244.jpeg" style="width:9.02778in;height:3.71458in" /></p>
<ul>
<li><blockquote>
<p>Semantic segmentation</p>
</blockquote>
<ul>
<li><blockquote>
<p>Classify all pixels</p>
</blockquote></li>
<li><blockquote>
<p>Fully convolutional models, downsample then upsample</p>
</blockquote></li>
<li><blockquote>
<p>Learnable upsampling: fractionally strided convolution</p>
</blockquote></li>
<li><blockquote>
<p>Skip connections can help</p>
</blockquote></li>
</ul></li>
<li><blockquote>
<p>Instance Segmentation</p>
</blockquote>
<ul>
<li><blockquote>
<p>Detect instance, generate mask</p>
</blockquote></li>
<li><blockquote>
<p>Similar pipelines to object detection</p>
</blockquote></li>
</ul></li>
</ul>
<p><img src="media/image245.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 79 24 Feb 2016</p>
<p><img src="media/image246.jpeg" style="width:9.02778in;height:0.96528in" /></p>
<p>Attention Models</p>
<p><img src="media/image247.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 80 24 Feb 2016</p>
<blockquote>
<p><img src="media/image248.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image249.jpeg" style="width:1.2375in;height:1.8875in" /></p>
<p>Image:</p>
<blockquote>
<p>H x W x 3</p>
</blockquote>
<p><img src="media/image250.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 81 24 Feb 2016</p>
<blockquote>
<p><img src="media/image251.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image252.jpeg" style="width:2.84792in;height:1.8875in" /></p>
<blockquote>
<p>CNN</p>
</blockquote>
<p><img src="media/image253.jpeg" style="width:1.10764in;height:0.7125in" /></p>
<blockquote>
<p><sup>Image:</sup> Features:</p>
<p>H x W x 3 <sub>D</sub></p>
</blockquote>
<p><img src="media/image254.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 82 24 Feb 2016</p>
<blockquote>
<p><img src="media/image255.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image256.jpeg" style="width:4.25417in;height:1.8875in" /></p>
<blockquote>
<p>CNN h0</p>
</blockquote>
<p><img src="media/image257.jpeg" style="width:2.49722in;height:1.45in" /></p>
<table>
<tbody>
<tr class="odd">
<td>Image:</td>
<td><blockquote>
<p>Features:</p>
</blockquote></td>
<td><blockquote>
<p>Hidden state:</p>
</blockquote></td>
</tr>
<tr class="even">
<td>H x W x 3</td>
<td><blockquote>
<p>D</p>
</blockquote></td>
<td><blockquote>
<p>H</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="media/image259.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 83 24 Feb 2016</p>
<blockquote>
<p><img src="media/image260.jpeg" style="width:9.02778in;height:1.37222in" /></p>
<p>Distribution</p>
<p>over vocab</p>
</blockquote>
<p><img src="media/image261.jpeg" style="width:0.44722in;height:0.5875in" /></p>
<blockquote>
<p>d1</p>
</blockquote>
<p><img src="media/image262.jpeg" style="width:2.40556in;height:1.8875in" /></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>h0</td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h1</p>
</blockquote></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Features:</td>
<td>Hidden state:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>H x W x 3</td>
<td>D</td>
<td></td>
<td>H</td>
<td></td>
<td><blockquote>
<p>y1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image265.jpeg" style="width:3.49583in;height:2.30278in" /></p>
<blockquote>
<p>First</p>
<p>word</p>
</blockquote>
<p><img src="media/image267.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 84 24 Feb 2016</p>
<blockquote>
<p><img src="media/image268.jpeg" style="width:9.02778in;height:1.37222in" /></p>
<p>Distribution</p>
<p>over vocab</p>
</blockquote>
<p><img src="media/image269.jpeg" style="width:0.44722in;height:0.5875in" /></p>
<blockquote>
<p>d1 d2</p>
</blockquote>
<p><img src="media/image271.jpeg" style="width:2.40556in;height:1.8875in" /></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>h0</td>
<td></td>
<td></td>
<td></td>
<td>h1</td>
<td></td>
<td></td>
<td></td>
<td>h2</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Features:</td>
<td>Hidden state:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>H x W x 3</td>
<td>D</td>
<td></td>
<td>H</td>
<td></td>
<td>y1</td>
<td></td>
<td></td>
<td></td>
<td>y2</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>First</td>
<td></td>
<td></td>
<td><blockquote>
<p>Second</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>word</td>
<td></td>
<td></td>
<td></td>
<td>word</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image276.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 85 24 Feb 2016</p>
<blockquote>
<p><img src="media/image279.jpeg" style="width:9.2875in;height:1.37222in" /></p>
<p>Distribution</p>
<p>over vocab</p>
</blockquote>
<p><img src="media/image280.jpeg" style="width:0.44722in;height:0.5875in" /></p>
<blockquote>
<p>d1 d2</p>
</blockquote>
<p><img src="media/image282.jpeg" style="width:2.40556in;height:1.8875in" /></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>h0</td>
<td></td>
<td></td>
<td></td>
<td>h1</td>
<td></td>
<td></td>
<td></td>
<td>h2</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Features:</td>
<td>Hidden state:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>H x W x 3</td>
<td>D</td>
<td></td>
<td>H</td>
<td></td>
<td>y1</td>
<td></td>
<td></td>
<td></td>
<td>y2</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>First</td>
<td></td>
<td></td>
<td><blockquote>
<p>Second</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>word</td>
<td></td>
<td></td>
<td></td>
<td>word</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image287.jpeg" style="width:10in;height:0.58889in" /></p>
<p>RNN only looks at whole image, once</p>
<p><img src="media/image290.jpeg" style="width:0.13056in;height:0.13056in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 86 24 Feb 2016</p>
<blockquote>
<p><img src="media/image291.jpeg" style="width:9.2875in;height:1.37222in" /></p>
<p>Distribution</p>
<p>over vocab</p>
</blockquote>
<p><img src="media/image292.jpeg" style="width:0.44722in;height:0.5875in" /></p>
<blockquote>
<p>d1 d2</p>
</blockquote>
<p><img src="media/image294.jpeg" style="width:2.40556in;height:1.8875in" /></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>h0</td>
<td></td>
<td></td>
<td></td>
<td>h1</td>
<td></td>
<td></td>
<td></td>
<td>h2</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Features:</td>
<td>Hidden state:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>H x W x 3</td>
<td>D</td>
<td></td>
<td>H</td>
<td></td>
<td>y1</td>
<td></td>
<td></td>
<td></td>
<td>y2</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>First</td>
<td></td>
<td></td>
<td><blockquote>
<p>Second</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>word</td>
<td></td>
<td></td>
<td></td>
<td>word</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image299.jpeg" style="width:10in;height:0.58889in" /></p>
<p>RNN only looks at whole image, once</p>
<p><img src="media/image302.jpeg" style="width:0.13056in;height:0.13056in" /></p>
<p>What if the RNN looks at different parts of the image at each timestep?</p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 87 24 Feb 2016</p>
<blockquote>
<p><img src="media/image304.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image305.jpeg" style="width:3.30069in;height:1.8875in" /></p>
<blockquote>
<p>CNN</p>
<p>Features:</p>
<p>Image: <sub>L x D</sub></p>
<p>H x W x 3</p>
</blockquote>
<p><img src="media/image306.jpeg" style="width:2.17361in;height:0.6125in" /></p>
<p>Xu et al, “Show, Attend and Tell: Neural</p>
<p>Image Caption Generation with Visual</p>
<p>Attention”, ICML 2015</p>
<p><img src="media/image307.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 88 24 Feb 2016</p>
<p><img src="media/image308.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image309.jpeg" style="width:4.25417in;height:1.8875in" /></p>
<blockquote>
<p>CNN <img src="media/image310.jpeg" style="width:0.42639in;height:0.15556in" /> h0</p>
</blockquote>
<p><img src="media/image312.jpeg" style="width:0.56597in" /></p>
<blockquote>
<p>Features:</p>
<p>Image: <sub>L x D</sub></p>
<p>H x W x 3</p>
</blockquote>
<p><img src="media/image314.jpeg" style="width:2.17361in;height:0.6125in" /></p>
<p>Xu et al, “Show, Attend and Tell: Neural</p>
<p>Image Caption Generation with Visual</p>
<p>Attention”, ICML 2015</p>
<p><img src="media/image315.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 89 24 Feb 2016</p>
<p><img src="media/image316.jpeg" style="width:9.02778in;height:1.34722in" /></p>
<p>L locations</p>
</blockquote>
<p><img src="media/image317.jpeg" style="width:0.44722in;height:1.69167in" /></p>
<blockquote>
<p>a1</p>
</blockquote>
<p><img src="media/image318.jpeg" style="width:3.30069in;height:1.8875in" /></p>
<blockquote>
<p>CNN <img src="media/image320.jpeg" style="width:0.42639in;height:0.15556in" /> h0</p>
</blockquote>
<p><img src="media/image322.jpeg" style="width:0.56597in" /></p>
<blockquote>
<p>Features:</p>
<p>Image: <sub>L x D</sub></p>
<p>H x W x 3</p>
</blockquote>
<p><img src="media/image324.jpeg" style="width:2.17361in;height:0.6125in" /></p>
<p>Xu et al, “Show, Attend and Tell: Neural</p>
<p>Image Caption Generation with Visual</p>
<p>Attention”, ICML 2015</p>
<p><img src="media/image325.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 90 24 Feb 2016</p>
<p><img src="media/image326.jpeg" style="width:9.02778in;height:1.34722in" /></p>
<p>L locations</p>
</blockquote>
<p><img src="media/image327.jpeg" style="width:5.30139in;height:3.39931in" /></p>
<p>CNN</p>
<p>Image:</p>
<blockquote>
<p>H x W x 3</p>
</blockquote>
<p>Xu et al, “Show, Attend and Tell: Neural Image Caption Generation with Visual Attention”, ICML 2015</p>
<blockquote>
<p>a1</p>
</blockquote>
<p><img src="media/image328.jpeg" style="height:0.43125in" /></p>
<blockquote>
<p>h0</p>
</blockquote>
<p><img src="media/image331.jpeg" style="width:0.56597in" /></p>
<p>Features:</p>
<blockquote>
<p>L x D</p>
<p>Weighted</p>
</blockquote>
<p>z1</p>
<blockquote>
<p>features: D</p>
</blockquote>
<p>Weighted</p>
<p>combination</p>
<p>of features</p>
<p><img src="media/image332.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 91 24 Feb 2016</p>
<p><img src="media/image333.jpeg" style="width:9.02778in;height:1.34722in" /></p>
<p>L locations</p>
</blockquote>
<p><img src="media/image334.jpeg" style="width:6.22847in;height:3.39931in" /></p>
<p>CNN</p>
<p>Image:</p>
<blockquote>
<p>H x W x 3</p>
</blockquote>
<p>Xu et al, “Show, Attend and Tell: Neural Image Caption Generation with Visual Attention”, ICML 2015</p>
<blockquote>
<p>a1</p>
</blockquote>
<p><img src="media/image335.jpeg" style="height:0.43125in" /></p>
<table>
<tbody>
<tr class="odd">
<td>h0</td>
<td><blockquote>
<p>h1</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="media/image338.jpeg" style="width:0.56597in" /></p>
<table>
<tbody>
<tr class="odd">
<td>Features:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>L x D</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Weighted</p>
</blockquote></td>
<td><blockquote>
<p>z1</p>
</blockquote></td>
<td></td>
<td></td>
<td>y1</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>features: D</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Weighted</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>combination</td>
<td></td>
<td>First word</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>of features</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image340.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 92 24 Feb 2016</p>
<p><img src="media/image341.jpeg" style="width:9.51389in;height:4.76458in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>L locations</td>
<td></td>
<td><blockquote>
<p>Distribution</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td><blockquote>
<p>over vocab</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>a1</td>
<td></td>
<td><blockquote>
<p>a2</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>d1</p>
</blockquote></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image342.jpeg" style="height:0.54514in" /></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h0</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Image:</td>
<td>Features:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>L x D</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>H x W x 3</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Weighted</td>
<td></td>
<td><blockquote>
<p>z1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>y1</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>features: D</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Weighted</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Xu et al, “Show, Attend and Tell: Neural</td>
<td><blockquote>
<p>combination</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>First word</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image Caption Generation with Visual</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>of features</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Attention”, ICML 2015</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image343.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 93 24 Feb 2016</p>
<p><img src="media/image348.jpeg" style="width:10in;height:5.41389in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>L locations</td>
<td></td>
<td><blockquote>
<p>Distribution</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td><blockquote>
<p>over vocab</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>a1</td>
<td><blockquote>
<p>a2</p>
</blockquote></td>
<td><blockquote>
<p>d1</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image349.jpeg" style="height:0.54514in" /></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h0</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Image:</td>
<td>Features:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>L x D</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>H x W x 3</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Weighted</td>
<td></td>
<td><blockquote>
<p>z1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>y1</td>
<td></td>
<td><blockquote>
<p>z2</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>features: D</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Weighted</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Xu et al, “Show, Attend and Tell: Neural</td>
<td><blockquote>
<p>combination</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>First word</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image Caption Generation with Visual</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>of features</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Attention”, ICML 2015</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image350.jpeg" style="width:0.56597in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 94 24 Feb 2016</p>
<p><img src="media/image354.jpeg" style="width:10in;height:5.41389in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>L locations</td>
<td></td>
<td><blockquote>
<p>Distribution</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td><blockquote>
<p>over vocab</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>a1</td>
<td><blockquote>
<p>a2</p>
</blockquote></td>
<td><blockquote>
<p>d1</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image355.jpeg" style="height:0.54514in" /></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h0</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h2</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image:</td>
<td>Features:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>L x D</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>H x W x 3</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Weighted</td>
<td></td>
<td><blockquote>
<p>z1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>y1</td>
<td></td>
<td></td>
<td><blockquote>
<p>z2</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>y2</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>features: D</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Weighted</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Xu et al, “Show, Attend and Tell: Neural</td>
<td><blockquote>
<p>combination</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>First word</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Image Caption Generation with Visual</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>of features</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Attention”, ICML 2015</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image356.jpeg" style="width:0.56597in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 95 24 Feb 2016</p>
<p><img src="media/image361.jpeg" style="width:10in;height:5.41389in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>L locations</td>
<td></td>
<td><blockquote>
<p>Distribution</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td><blockquote>
<p>over vocab</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>a1</td>
<td><blockquote>
<p>a2</p>
</blockquote></td>
<td><blockquote>
<p>d1</p>
</blockquote></td>
<td><blockquote>
<p>a3</p>
</blockquote></td>
<td><blockquote>
<p>d2</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image362.jpeg" style="height:0.54514in" /></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h0</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h2</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image:</td>
<td>Features:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>L x D</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>H x W x 3</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Weighted</td>
<td></td>
<td><blockquote>
<p>z1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>y1</td>
<td></td>
<td></td>
<td><blockquote>
<p>z2</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>y2</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>features: D</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Weighted</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Xu et al, “Show, Attend and Tell: Neural</td>
<td><blockquote>
<p>combination</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>First word</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Image Caption Generation with Visual</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>of features</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Attention”, ICML 2015</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image363.jpeg" style="width:0.56597in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 96 24 Feb 2016</p>
<p><img src="media/image368.jpeg" style="width:10in;height:5.41389in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>Guess which framework</td>
<td><blockquote>
<p>L locations</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>Distribution</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>was used to implement?</td>
<td></td>
<td></td>
<td><blockquote>
<p>over vocab</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>a1</td>
<td></td>
<td><blockquote>
<p>a2</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>d1</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>a3</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>d2</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image369.jpeg" style="height:0.54514in" /></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h0</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>h2</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image:</td>
<td>Features:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>L x D</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>H x W x 3</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Weighted</td>
<td></td>
<td><blockquote>
<p>z1</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>y1</td>
<td></td>
<td></td>
<td><blockquote>
<p>z2</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>y2</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>features: D</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Weighted</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Xu et al, “Show, Attend and Tell: Neural</td>
<td><blockquote>
<p>combination</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>First word</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Image Caption Generation with Visual</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>of features</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Attention”, ICML 2015</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image370.jpeg" style="width:0.56597in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 97 24 Feb 2016</p>
<p><img src="media/image375.jpeg" style="width:10in;height:5.41389in" /></p>
<p>Guess which framework was used to implement?</p>
<p>Crazy RNN = <strong>Theano</strong></p>
<p>CNN</p>
</blockquote>
<p>Image:</p>
<blockquote>
<p>H x W x 3</p>
</blockquote>
<p>Xu et al, “Show, Attend and Tell: Neural Image Caption Generation with Visual Attention”, ICML 2015</p>
<table>
<tbody>
<tr class="odd">
<td>L locations</td>
<td></td>
<td><blockquote>
<p>Distribution</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td><blockquote>
<p>over vocab</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>a1</td>
<td><blockquote>
<p>a2</p>
</blockquote></td>
<td><blockquote>
<p>d1</p>
</blockquote></td>
<td><blockquote>
<p>a3</p>
</blockquote></td>
<td><blockquote>
<p>d2</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image376.jpeg" style="height:0.43125in" /></p>
<table>
<tbody>
<tr class="odd">
<td>h0</td>
<td><blockquote>
<p>h1</p>
</blockquote></td>
<td><blockquote>
<p>h2</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="media/image379.jpeg" style="width:0.56597in" /></p>
<table>
<tbody>
<tr class="odd">
<td>Features:</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>L x D</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Weighted</p>
</blockquote></td>
<td><blockquote>
<p>z1</p>
</blockquote></td>
<td>y1</td>
<td><blockquote>
<p>z2</p>
</blockquote></td>
<td><blockquote>
<p>y2</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>features: D</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Weighted</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>combination</td>
<td></td>
<td>First word</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>of features</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 98 24 Feb 2016</p>
<p><img src="media/image382.jpeg" style="width:9.31111in;height:2.82986in" /></p>
<p>Image:</p>
<p>H x W x 3</p>
<p>From</p>
<p>RNN:</p>
<p>a b</p>
</blockquote>
<p>CNN</p>
<blockquote>
<p>c d</p>
</blockquote>
<p>Grid of features</p>
<p>(Each D-</p>
<p>dimensional)</p>
<p><img src="media/image383.jpeg" style="width:4.21944in;height:1.74306in" /></p>
<blockquote>
<p>p<sub>a</sub> p<sub>b</sub></p>
<p>p<sub>c</sub> p<sub>d</sub></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Distribution over</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td>Xu et al, “Show, Attend and Tell: Neural</td>
<td><blockquote>
<p>grid locations</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>Image Caption Generation with Visual</td>
<td><blockquote>
<p>p<sub>a</sub> + p<sub>b</sub> + p<sub>c</sub> + p<sub>c</sub> = 1</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Attention”, ICML 2015</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image384.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 99 24 Feb 2016</p>
<p><img src="media/image385.jpeg" style="width:9.51389in;height:4.76458in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td>a</td>
<td>b</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td>c</td>
<td>d</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image:</td>
<td>Grid of features</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td>(Each D-</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>H x W x 3</td>
<td></td>
<td>dimensional)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>From</td>
<td></td>
<td></td>
<td>p<sub>a</sub></td>
<td>p<sub>b</sub></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>RNN:</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>p<sub>c</sub></td>
<td>p<sub>d</sub></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>Distribution over</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Xu et al, “Show, Attend and Tell: Neural</td>
<td></td>
<td>grid locations</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td>Image Caption Generation with Visual</td>
<td><blockquote>
<p>p<sub>a</sub> + p<sub>b</sub> + p<sub>c</sub> + p<sub>c</sub> = 1</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Attention”, ICML 2015</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Context vector z</p>
<blockquote>
<p>(D-dimensional)</p>
</blockquote>
<p><img src="media/image386.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 100 24 Feb 2016</p>
<p><img src="media/image387.jpeg" style="width:9.65486in;height:4.76458in" /></p>
<p><strong>Soft attention:</strong></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td>a</td>
<td>b</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td>c</td>
<td>d</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image:</td>
<td>Grid of features</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td>(Each D-</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>H x W x 3</td>
<td></td>
<td>dimensional)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>From</td>
<td></td>
<td></td>
<td>p<sub>a</sub></td>
<td>p<sub>b</sub></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>RNN:</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>p<sub>c</sub></td>
<td>p<sub>d</sub></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>Distribution over</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Xu et al, “Show, Attend and Tell: Neural</td>
<td></td>
<td>grid locations</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td>Image Caption Generation with Visual</td>
<td><blockquote>
<p>p<sub>a</sub> + p<sub>b</sub> + p<sub>c</sub> + p<sub>c</sub> = 1</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Attention”, ICML 2015</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Context vector z</p>
<blockquote>
<p>(D-dimensional)</p>
</blockquote>
<p><img src="media/image388.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Summarize ALL locations</p>
<p>z = p<sub>a</sub>a+ p<sub>b</sub>b + p<sub>c</sub>c + p<sub>d</sub>d</p>
<p>Derivative dz/dp is nice!</p>
<p>Train with gradient descent</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 101 24 Feb 2016</p>
<p><img src="media/image389.jpeg" style="width:9.79167in;height:4.79722in" /></p>
<p><strong>Soft attention:</strong></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td><blockquote>
<p>CNN</p>
</blockquote></td>
<td></td>
<td></td>
<td>a</td>
<td>b</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td>c</td>
<td>d</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Image:</td>
<td>Grid of features</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td>(Each D-</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>H x W x 3</td>
<td></td>
<td>dimensional)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>From</td>
<td></td>
<td></td>
<td>p<sub>a</sub></td>
<td>p<sub>b</sub></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>RNN:</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td>p<sub>c</sub></td>
<td>p<sub>d</sub></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>Distribution over</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Xu et al, “Show, Attend and Tell: Neural</td>
<td></td>
<td>grid locations</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td>Image Caption Generation with Visual</td>
<td><blockquote>
<p>p<sub>a</sub> + p<sub>b</sub> + p<sub>c</sub> + p<sub>c</sub> = 1</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Attention”, ICML 2015</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Context vector z</p>
<blockquote>
<p>(D-dimensional)</p>
</blockquote>
<p><img src="media/image390.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Summarize ALL locations</p>
<p>z = p<sub>a</sub>a+ p<sub>b</sub>b + p<sub>c</sub>c + p<sub>d</sub>d</p>
<p>Derivative dz/dp is nice!</p>
<p>Train with gradient descent</p>
<p><strong>Hard attention</strong>:</p>
<p>Sample ONE location</p>
<p>according to p, z = that vector</p>
<p>With argmax, dz/dp is zero</p>
<p>almost everywhere …</p>
<blockquote>
<p>Can’t use gradient descent; need reinforcement learning</p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 102 24 Feb 2016</p>
<p><img src="media/image391.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image392.jpeg" style="width:9.76181in;height:2.075in" /></p>
<blockquote>
<p>Soft attention</p>
<p>Hard attention</p>
</blockquote>
<p><img src="media/image393.jpeg" style="width:2.17361in;height:0.6125in" /></p>
<p>Xu et al, “Show, Attend and Tell: Neural</p>
<p>Image Caption Generation with Visual</p>
<p>Attention”, ICML 2015</p>
<p><img src="media/image394.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 103 24 Feb 2016</p>
<p><img src="media/image395.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image396.jpeg" style="width:8.55069in;height:3.68194in" /></p>
<p>Xu et al, “Show, Attend and Tell: Neural</p>
<p>Image Caption Generation with Visual</p>
<p>Attention”, ICML 2015</p>
<p><img src="media/image397.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 104 24 Feb 2016</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>Soft Attention for Captioning</td>
<td><blockquote>
<p>Attention constrained to</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>fixed grid! We’ll come</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>back to this ….</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image398.jpeg" style="width:9.31528in;height:1.08958in" /></p>
<p>Xu et al, “Show, Attend and Tell: Neural</p>
<p>Image Caption Generation with Visual</p>
<p>Attention”, ICML 2015</p>
<p><img src="media/image472.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 105 24 Feb 2016</p>
<p><img src="media/image473.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image474.jpeg" style="width:9.83958in;height:3.71458in" /></p>
<blockquote>
<p>“Mi gato es el mejor” -&gt; “My cat is the best”</p>
</blockquote>
<p>Bahdanau et al, “Neural Machine Translation by</p>
<p>Jointly Learning to Align and Translate”, ICLR 2015</p>
<p><img src="media/image475.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 106 24 Feb 2016</p>
<p><img src="media/image476.jpeg" style="width:9.83958in;height:4.80208in" /></p>
</blockquote>
<p>Distribution over</p>
<p>input words</p>
<p><img src="media/image477.jpeg" style="height:0.89167in" /></p>
<blockquote>
<p>“Mi gato es el mejor” -&gt; “My cat is the best”</p>
</blockquote>
<p>Bahdanau et al, “Neural Machine Translation by</p>
<p>Jointly Learning to Align and Translate”, ICLR 2015</p>
<p><img src="media/image482.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 107 24 Feb 2016</p>
<p><img src="media/image483.jpeg" style="width:9.83958in;height:4.80208in" /></p>
</blockquote>
<p>Distribution over</p>
<p>input words</p>
<p><img src="media/image484.jpeg" style="height:0.16458in" /></p>
<blockquote>
<p>“Mi gato es el mejor” -&gt; “My cat is the best”</p>
</blockquote>
<p>Bahdanau et al, “Neural Machine Translation by</p>
<p>Jointly Learning to Align and Translate”, ICLR 2015</p>
<p><img src="media/image489.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 108 24 Feb 2016</p>
<p><img src="media/image490.jpeg" style="width:9.83958in;height:4.80208in" /></p>
</blockquote>
<p>Distribution over</p>
<p>input words</p>
<p><img src="media/image491.jpeg" style="height:0.16458in" /></p>
<blockquote>
<p>“Mi gato es el mejor” -&gt; “My cat is the best”</p>
</blockquote>
<p>Bahdanau et al, “Neural Machine Translation by</p>
<p>Jointly Learning to Align and Translate”, ICLR 2015</p>
<p><img src="media/image496.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 109 24 Feb 2016</p>
<p><img src="media/image497.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image498.jpeg" style="width:9.90764in;height:3.53958in" /></p>
<blockquote>
<p><strong>Machine Translation, attention over input:</strong></p>
<p>- Luong et al, “Effective Approaches to Attention-based Neural Machine Translation,” EMNLP 2015</p>
<p><strong>Speech recognition, attention over input sounds:</strong></p>
</blockquote>
<ul>
<li><blockquote>
<p>Chan et al, “Listen, Attend, and Spell”, arXiv 2015</p>
</blockquote></li>
<li><blockquote>
<p>Chorowski et al, “Attention-based models for Speech Recognition”, NIPS 2015</p>
</blockquote></li>
</ul>
<p><strong>Video captioning,</strong></p>
<p><strong>attention over input frames:</strong></p>
<ul>
<li><p>Yao et al, “Describing Videos by Exploiting Temporal Structure”, ICCV 2015</p></li>
</ul>
<p><img src="media/image499.jpeg" style="width:10in;height:0.58889in" /></p>
<p><strong>Image, question to answer, attention over image:</strong></p>
<ul>
<li><p>Xu and Saenko, “Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering”, arXiv 2015</p></li>
<li><p>Zhu et al, “Visual7W: Grounded Question Answering in Images”, arXiv 2015</p></li>
</ul>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 110 24 Feb 2016</p>
<blockquote>
<p><img src="media/image500.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image501.jpeg" style="height:1.06181in" /></p>
<blockquote>
<p>Features:</p>
</blockquote>
<p><img src="media/image513.jpeg" style="width:1.06181in" /></p>
<blockquote>
<p>Image: <sub>L x D</sub></p>
<p>H x W x 3</p>
</blockquote>
<p><img src="media/image514.jpeg" style="width:6.79514in;height:0.58125in" /></p>
<blockquote>
<p>Attention mechanism from Show, Attend, and Tell only lets us softly attend to fixed grid positions … can we do better?</p>
</blockquote>
<p><img src="media/image515.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 111 24 Feb 2016</p>
<blockquote>
<p><img src="media/image516.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image517.jpeg" style="width:4.48056in;height:0.96528in" /></p>
<ul>
<li><blockquote>
<p>Read text, generate handwriting using an RNN</p>
</blockquote></li>
<li><blockquote>
<p>Attend to arbitrary regions of the <strong>output</strong> by predicting params of a mixture model</p>
</blockquote></li>
</ul>
<p><img src="media/image518.jpeg" style="width:10in;height:3.39167in" /></p>
<p>Graves, “Generating Sequences with Recurrent Neural Networks”, arXiv 2013</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 112 24 Feb 2016</p>
<p><img src="media/image519.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image520.jpeg" style="width:4.48056in;height:0.96528in" /></p>
<ul>
<li><blockquote>
<p>Read text, generate handwriting using an RNN</p>
</blockquote></li>
<li><blockquote>
<p>Attend to arbitrary regions of the <strong>output</strong> by predicting params of a mixture model</p>
</blockquote></li>
</ul>
<p><img src="media/image521.jpeg" style="width:10in;height:3.39167in" /></p>
<p>Which are real and which are generated?</p>
<p><img src="media/image522.jpeg" style="width:4.48056in;height:2.99583in" /></p>
<p>Graves, “Generating Sequences with Recurrent Neural Networks”, arXiv 2013</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 113 24 Feb 2016</p>
<p><img src="media/image524.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image525.jpeg" style="width:10in;height:4.40278in" /></p>
<ul>
<li><blockquote>
<p>Read text, generate handwriting using an RNN</p>
</blockquote></li>
<li><blockquote>
<p>Attend to arbitrary regions of the <strong>output</strong> by predicting params of a mixture model</p>
</blockquote></li>
</ul>
<p>Which are real and which are generated?</p>
<blockquote>
<p><strong>REAL</strong></p>
</blockquote>
<p>Graves, “Generating Sequences with Recurrent Neural Networks”, arXiv 2013</p>
<p><strong>GENERATED</strong></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 114 24 Feb 2016</p>
<p><img src="media/image526.jpeg" style="width:10in;height:5.41389in" /></p>
<p><strong>Classify</strong> images by attending to</p>
<p>arbitrary regions of the <em>input</em></p>
</blockquote>
<p>Gregor et al, “DRAW: A Recurrent Neural Network For Image Generation”, ICML 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 115 24 Feb 2016</p>
<p><img src="media/image527.jpeg" style="width:10in;height:5.41389in" /></p>
<p><strong>Classify</strong> images by attending to</p>
<p>arbitrary regions of the <em>input</em></p>
</blockquote>
<p><strong>Generate</strong> images by attending to arbitrary regions of the <em>output</em></p>
<p>Gregor et al, “DRAW: A Recurrent Neural Network For Image Generation”, ICML 2015</p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 116 24 Feb 2016</p>
</blockquote>
<p><img src="media/image528.jpeg" style="width:10in;height:5.37083in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 117 24 Feb 2016</p>
<blockquote>
<p><img src="media/image529.jpeg" style="width:9.02778in;height:0.96528in" /></p>
<p>Spatial Transformer Networks</p>
</blockquote>
<p><img src="media/image530.jpeg" style="width:9.02778in;height:1.67431in" /></p>
<blockquote>
<p>Attention mechanism similar to DRAW, but easier to explain</p>
</blockquote>
<p><img src="media/image531.jpeg" style="width:3.96111in;height:0.31042in" /></p>
<p>Jaderberg et al, “Spatial Transformer Networks”, NIPS 2015</p>
<p><img src="media/image532.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 118 24 Feb 2016</p>
<p><img src="media/image533.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image534.jpeg" style="width:4.6in;height:2.84722in" /></p>
<blockquote>
<p>Input image:</p>
<p>H x W x 3 Cropped and</p>
<p>rescaled image:</p>
</blockquote>
<p>X x Y x 3</p>
<p><img src="media/image535.jpeg" style="width:1.89167in;height:0.62917in" /></p>
<p>Box Coordinates:</p>
<blockquote>
<p>(xc, yc, w, h)</p>
</blockquote>
<p><img src="media/image536.jpeg" style="width:3.96111in;height:0.31042in" /></p>
<p>Jaderberg et al, “Spatial Transformer Networks”, NIPS 2015</p>
<p><img src="media/image537.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 119 24 Feb 2016</p>
<p><img src="media/image538.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image539.jpeg" style="width:4.12431in;height:1.67361in" /></p>
<p>Can we make this</p>
<p>function differentiable?</p>
<p><img src="media/image540.jpeg" style="width:4.43194in;height:1.86736in" /></p>
<blockquote>
<p>Input image:</p>
<p>H x W x 3 Cropped and</p>
<p>rescaled image:</p>
</blockquote>
<p>X x Y x 3</p>
<p><img src="media/image542.jpeg" style="width:1.89167in;height:0.62917in" /></p>
<p>Box Coordinates:</p>
<blockquote>
<p>(xc, yc, w, h)</p>
</blockquote>
<p><img src="media/image543.jpeg" style="width:3.96111in;height:0.31042in" /></p>
<p>Jaderberg et al, “Spatial Transformer Networks”, NIPS 2015</p>
<p><img src="media/image544.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 120 24 Feb 2016</p>
<p><img src="media/image545.jpeg" style="width:9.02778in;height:4.33472in" /></p>
<p>Can we make this</p>
<p>function differentiable?</p>
<p>Input image:</p>
<p>H x W x 3 Cropped and rescaled image:</p>
<p>X x Y x 3</p>
</blockquote>
<p>Box Coordinates:</p>
<blockquote>
<p>(xc, yc, w, h)</p>
</blockquote>
<p><img src="media/image546.jpeg" style="width:3.96111in;height:0.31042in" /></p>
<p><strong>Idea</strong>: Function mapping <em>pixel coordinates</em> (xt, yt) of output to <em>pixel coordinates</em> (xs, ys) of input</p>
<p>Jaderberg et al, “Spatial Transformer Networks”, NIPS 2015</p>
<p><img src="media/image547.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 121 24 Feb 2016</p>
<p><img src="media/image548.jpeg" style="width:9.02778in;height:4.33472in" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td>(x<sup>s</sup>, y<sup>s</sup>)</td>
<td>Can we make this</td>
</tr>
<tr class="even">
<td></td>
<td>function differentiable?</td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>(x<sup>t</sup>, y<sup>t</sup>)</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>Input image:</p>
<p>H x W x 3 Cropped and rescaled image:</p>
<p>X x Y x 3</p>
</blockquote>
<p>Box Coordinates:</p>
<blockquote>
<p>(xc, yc, w, h)</p>
</blockquote>
<p><img src="media/image549.jpeg" style="width:3.96111in;height:0.31042in" /></p>
<p><strong>Idea</strong>: Function mapping <em>pixel coordinates</em> (xt, yt) of output to <em>pixel coordinates</em> (xs, ys) of input</p>
<p>Jaderberg et al, “Spatial Transformer Networks”, NIPS 2015</p>
<p><img src="media/image550.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 122 24 Feb 2016</p>
<p><img src="media/image551.jpeg" style="width:9.02778in;height:4.33472in" /></p>
<p>(x<sup>s</sup>, y<sup>s</sup>)</p>
<p>Input image:</p>
<p>H x W x 3</p>
<p>Box Coordinates:</p>
<p>(xc, yc, w, h)</p>
</blockquote>
<p><img src="media/image552.jpeg" style="width:3.96111in;height:0.31042in" /></p>
<p>Can we make this</p>
<p>function differentiable?</p>
<blockquote>
<p>(x<sup>t</sup>, y<sup>t</sup>)</p>
<p>Cropped and</p>
<p>rescaled image:</p>
<p>X x Y x 3</p>
</blockquote>
<p><strong>Idea</strong>: Function mapping <em>pixel coordinates</em> (xt, yt) of output to <em>pixel coordinates</em> (xs, ys) of input</p>
<p>Jaderberg et al, “Spatial Transformer Networks”, NIPS 2015</p>
<p><img src="media/image553.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 123 24 Feb 2016</p>
<p><img src="media/image554.jpeg" style="width:9.97569in;height:4.81319in" /></p>
<p>Can we make this</p>
<p>function differentiable?</p>
</blockquote>
<p><strong>Idea</strong>: Function mapping</p>
<p><em>pixel coordinates</em> (xt, yt) of</p>
<p>output to <em>pixel coordinates</em></p>
<p>(xs, ys) of input</p>
<table>
<tbody>
<tr class="odd">
<td>Input image:</td>
<td></td>
<td><blockquote>
<p>Repeat for all pixels</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Cropped and</td>
<td><blockquote>
<p>in <em>output</em> to get a</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>H x W x 3</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>rescaled image:</td>
<td><blockquote>
<p><strong>sampling grid</strong></p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>X x Y x 3</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Box Coordinates:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>(xc, yc, w, h)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Jaderberg et al, “Spatial Transformer Networks”, NIPS 2015</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/image555.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 124 24 Feb 2016</p>
<p><img src="media/image556.jpeg" style="width:9.97569in;height:4.81319in" /></p>
<p>Can we make this</p>
<p>function differentiable?</p>
</blockquote>
<p><strong>Idea</strong>: Function mapping</p>
<p><em>pixel coordinates</em> (xt, yt) of</p>
<p>output to <em>pixel coordinates</em></p>
<p>(xs, ys) of input</p>
<table>
<tbody>
<tr class="odd">
<td>Input image:</td>
<td></td>
<td><blockquote>
<p>Repeat for all pixels</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Cropped and</td>
<td><blockquote>
<p>in <em>output</em> to get a</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>H x W x 3</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>rescaled image:</td>
<td><blockquote>
<p><strong>sampling grid</strong></p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>X x Y x 3</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Then use <strong>bilinear</strong></p>
<blockquote>
<p>Box Coordinates:</p>
<p><strong>interpolation</strong> to</p>
<p>(xc, yc, w, h)</p>
<p>compute output</p>
</blockquote>
<p>Jaderberg et al, “Spatial Transformer Networks”, NIPS 2015</p>
<p><img src="media/image557.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 125 24 Feb 2016</p>
<p><img src="media/image558.jpeg" style="width:9.97569in;height:4.81319in" /></p>
<p>Can we make this</p>
<p>function differentiable?</p>
<p>Input image:</p>
<p>H x W x 3 Cropped and rescaled image:</p>
<p>X x Y x 3</p>
</blockquote>
<p>Box Coordinates:</p>
<blockquote>
<p>(xc, yc, w, h)</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><strong>Idea</strong>: Function mapping</td>
<td><blockquote>
<p>Network</p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>attends to</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td><em>pixel coordinates</em> (xt, yt) of</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>input by</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>output to <em>pixel coordinates</em></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>predicting</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td>(xs, ys) of input</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Repeat for all pixels in <em>output</em> to get a <strong>sampling grid</strong></p>
<p>Then use <strong>bilinear</strong></p>
<blockquote>
<p><strong>interpolation</strong> to compute output</p>
</blockquote>
<p>Jaderberg et al, “Spatial Transformer Networks”, NIPS 2015</p>
<p><img src="media/image559.jpeg" style="width:10in;height:0.58889in" /></p>
<blockquote>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 126 24 Feb 2016</p>
<p><img src="media/image560.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image561.jpeg" style="width:7.65417in;height:1.98681in" /></p>
<table>
<tbody>
<tr class="odd">
<td><strong>Input</strong>:</td>
<td><strong>Output:</strong> Region of</td>
</tr>
<tr class="even">
<td>Full image</td>
<td>interest from input</td>
</tr>
</tbody>
</table>
<p><img src="media/image562.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 127 24 Feb 2016</p>
<blockquote>
<p><img src="media/image563.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image564.jpeg" style="width:7.70625in;height:2.68819in" /></p>
<ul>
<li><blockquote>
<p>small</p>
</blockquote></li>
</ul>
<blockquote>
<p><strong>Localization network</strong></p>
<p>predicts transform</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><strong>Input</strong>:</td>
<td><strong>Output:</strong> Region of</td>
</tr>
<tr class="even">
<td>Full image</td>
<td>interest from input</td>
</tr>
</tbody>
</table>
<p><img src="media/image565.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 128 24 Feb 2016</p>
<blockquote>
<p><img src="media/image566.jpeg" style="width:9.02778in;height:3.90486in" /></p>
<p><strong>Grid generator</strong> uses to</p>
<p>compute sampling grid</p>
</blockquote>
<ul>
<li><blockquote>
<p>small</p>
</blockquote></li>
</ul>
<blockquote>
<p><strong>Localization network</strong></p>
<p>predicts transform</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><strong>Input</strong>:</td>
<td><strong>Output:</strong> Region of</td>
</tr>
<tr class="even">
<td>Full image</td>
<td>interest from input</td>
</tr>
</tbody>
</table>
<p><img src="media/image567.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 129 24 Feb 2016</p>
<blockquote>
<p><img src="media/image568.jpeg" style="width:9.02778in;height:4.77361in" /></p>
<p><strong>Grid generator</strong> uses to</p>
<p>compute sampling grid</p>
</blockquote>
<ul>
<li><blockquote>
<p>small</p>
</blockquote></li>
</ul>
<blockquote>
<p><strong>Localization network</strong></p>
<p>predicts transform</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><strong>Input</strong>:</td>
<td><strong>Output:</strong> Region of</td>
</tr>
<tr class="even">
<td>Full image</td>
<td>interest from input</td>
</tr>
</tbody>
</table>
<p><strong>Sampler</strong> uses</p>
<p>bilinear interpolation</p>
<p>to produce output</p>
<p><img src="media/image569.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 130 24 Feb 2016</p>
<blockquote>
<p><img src="media/image570.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image571.jpeg" style="width:4.39583in;height:2.74861in" /></p>
<blockquote>
<p>Insert spatial transformers into a</p>
<p>classification network and it learns</p>
<p>to attend and transform the input</p>
</blockquote>
<p><img src="media/image572.jpeg" style="width:2.38333in;height:0.61319in" /></p>
<blockquote>
<p>Differentiable “attention /</p>
<p>transformation” module</p>
</blockquote>
<p><img src="media/image573.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 131 24 Feb 2016</p>
<p><img src="media/image575.jpeg" style="width:10in;height:5.58333in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 132 24 Feb 2016</p>
<blockquote>
<p><img src="media/image576.jpeg" style="width:9.02778in;height:0.96528in" /></p>
</blockquote>
<p><img src="media/image577.jpeg" style="width:9.02778in;height:3.71458in" /></p>
<ul>
<li><blockquote>
<p>Soft attention:</p>
</blockquote>
<ul>
<li><blockquote>
<p>Easy to implement: produce distribution over input locations, reweight features and feed as input</p>
</blockquote></li>
<li><blockquote>
<p>Attend to arbitrary input locations using spatial transformer networks</p>
</blockquote></li>
</ul></li>
<li><blockquote>
<p>Hard attention:</p>
</blockquote>
<ul>
<li><blockquote>
<p>Attend to a single input location</p>
</blockquote></li>
<li><blockquote>
<p>Can’t use gradient descent!</p>
</blockquote></li>
<li><blockquote>
<p>Need <strong>reinforcement learning!</strong></p>
</blockquote></li>
</ul></li>
</ul>
<p><img src="media/image578.jpeg" style="width:10in;height:0.58889in" /></p>
<p>Fei-Fei Li &amp; Andrej Karpathy &amp; Justin Johnson Lecture 13 133 24 Feb 2016</p>
